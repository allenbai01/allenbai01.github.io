# jemdoc: menu{MENU}{index.html}
= Yu Bai

~~~
{}{img_left}{yub.png}{Yu Bai}{180}{240}{}

*About me*: I am a fourth-year PhD student in
[https://statistics.stanford.edu/ Statistics] at
[http://www.stanford.edu/ Stanford University], where I am fortunate
to be advised by [https://stanford.edu/~jduchi/ John Duchi]. My
research interest lies broadly in the span of machine learning,
optimization, and statistics. I am particularly interested in
non-convex / non-smooth geometries and theories of deep learning.

I am delighted to complement my research with industrial
experiences. I spent a wonderful summer at
[https://research.google.com Google Research] in 2016 working with
[https://research.google.com/pubs/LiZhang.html Li Zhang]. Currently
(summer 2018) I am working as a research intern in Amazon AI at Palo
Alto.

Prior to Stanford, I was an undergrad in mathematics at
[http://www.pku.edu.cn/ Peking University].

*Contact*:

Sequoia Hall \n
390 Serra Mall, Stanford, CA 94305

yub (at) stanford.edu
~~~

== Publications
- [https://arxiv.org/pdf/1805.08756.pdf On the Connection Between
  Sequential Quadratic Programming and Riemannian Gradient
  Methods.] \n Yu Bai, Song Mei, 2018. 
  
- [https://arxiv.org/abs/1707.03073 TAPAS: Two-pass Approximate
  Adaptive Sampling for Softmax.]~Yu Bai,
  Sally Goldman, and Li Zhang, 2017. 

- [https://arxiv.org/abs/1607.06534 The Landscape of Empirical Risk
  for Nonconvex Losses.]~Song Mei, Yu
  Bai, and Andrea Montanari, 2016.
  \n /To appear in the Annals of Statistics./
