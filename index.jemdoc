# jemdoc: menu{MENU}{index.html}
= Yu Bai

~~~
{}{img_left}{yub_square.jpg}{Yu Bai}{180}{180}{}

Yu Bai \n
Email: yu.bai (at) salesforce (dot) com

[Yu_Bai_CV.pdf Curriculum Vitae] |
[https://scholar.google.com/citations?user=owqhKD8AAAAJ&hl=en&authuser=1
Google Scholar Profile] | [https://github.com/allenbai01 Github]

{{<a href="https://twitter.com/yubai01?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @yubai01</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>}}

~~~

== About Me
I am a Senior Research Scientist at [https://www.salesforceairesearch.com/ Salesforce AI Research] in Palo Alto, CA. My research interest lies broadly in machine learning, such as deep learning, reinforcement learning, learning in games, and uncertainty quantification.

Before joining Salesforce, I completed my PhD in [https://statistics.stanford.edu/ Statistics] at [http://www.stanford.edu/ Stanford University] (specializing in machine learning) in September 2019, where I was fortunate to be advised by Prof. [https://stanford.edu/~jduchi/ John Duchi] and was a member of the [http://ml.stanford.edu/ Machine Learning Group]. During my PhD I also spent times at the research labs of Google and Amazon. Prior to Stanford, I was an undergrad in mathematics at [http://www.pku.edu.cn/ Peking University].

# During my PhD, I also spent two summers in research labs in the industry: at [https://research.google.com Google Research] in 2016, and at Amazon AI Palo Alto in 2018.

My research interest lies broadly in machine learning, with recent focus on
- Theoretical foundations of deep learning ([https://blog.salesforceairesearch.com/beyond-ntk/ blog post]);
- Reinforcement learning theory ([https://yubai.org/Slides/pomdp.pdf slides] on partially observable RL);
- Multi-agent reinforcement learning and games  ([https://yubai.org/blog/marl_theory.html blog post], [https://yubai.org/Slides/marl_lecture.pdf slides] on MARL, [https://yubai.org/Slides/efg.pdf slides] on Extensive-Form Games);
- Uncertainty quantification ([https://yubai.org/Slides/uncertainty.pdf slides]).

# My recent focus is on the theoretical foundations of deep learning, reinforcement learning, representation learning, and uncertainty quantification.

*News*:

# - *{{<font color="DarkBlue">Looking for self-motivated interns for summer 2021!</font>}}*

- \[May 2023\] Invited talk at SIAM OP23, Seattle.

- \[Apr 2023\] Three papers accepted at ICML 2023.

- \[Mar 2023\] I will serve as an Area Chair for NeurIPS 2023.

- \[Jan 2023\] Three papers accepted at ICLR 2023.

- \[Nov 2022\] Excited to be giving an invited talk "Recent Progresses on the Theory of Multi-Agent Reinforcement Learning and Games" at [https://cs332.stanford.edu Stanford CS332].

- \[Sep 2022\] Four papers accepted at NeurIPS 2022.

- \[May 2022\] Excited to be speaking at the [https://sites.google.com/view/rltheoryseminars/home?authuser=0 RL theory seminar] about our [https://arxiv.org/abs/2110.04184 work] on sample-efficient learning of general-sum Markov Games with a large number of players!

# - \[May 2022\] Our [http://arxiv.org/abs/2202.01752 paper] on near-optimal learning in extensive-form games is accepted at ICML 2022. We achieve this by two new algorithms (Balanced OMD, Balanced CFR).

# - \[Jan 2022\] Two papers accepted at ICLR 2022, on [https://arxiv.org/abs/2110.04184 sample-efficient RL in multi-agent general-sum Markov games], and [https://arxiv.org/abs/2202.11091 improved conformal prediction with general families of prediction sets].

# - \[Nov 2021\] New [https://yubai.org/blog/marl_theory.html blog post] (with Chi Jin) on recent progresses in multi-agent RL theory released!

# - \[Oct 2021\] Invited talk at Rutgers University ([https://statistics.rutgers.edu/news-events/seminars statistics department seminar]) on understanding the under-coverage bias in [https://arxiv.org/abs/2106.05515 uncertainty estimation] and [https://arxiv.org/abs/2102.07856 calibration].

# - \[Sep 2021\] Four papers accepted at NeurIPS 2021.

# - \[May 2021\] Four papers accepted at ICML 2021.

# - \[Mar 2021\] New blog post (cross-posted at [https://blog.einstein.ai/beyond-ntk/ Salesforce Research blog] and [http://www.offconvex.org/2021/03/25/beyondNTK/ off the convex path]) on our "Beyond NTK" line of work. We explore how to escape the "NTK ball" around the initialization, and why that can bring provable learning benefits to neural networks for learning certain functions.

# - \[Sep 2020\] Two papers accepted by NeurIPS 2020. Topics include  [https://arxiv.org/abs/2006.13436 new understandings of hierarchical learning in neural networks], and [https://arxiv.org/abs/2006.12007 near-optimal self-play algorithms for learning zero-sum Markov games].

# - \[May 2020\] Our [https://arxiv.org/abs/2002.04017 paper] on self-play is accepted by ICML 2020. We present the first line of provable self-play algorithms for two-player Markov games.

# - In October 2019, I will be joining [https://einstein.ai/ Salesforce Research] in Palo Alto as a research scientist. 

# - I am attending the [https://simons.berkeley.edu/programs/dl2019 Foundations of Deep Learning] program at the Simons Institute (Berkeley) as a research fellow in May - August 2019. 


== Recent Work

- [https://arxiv.org/abs/2302.06606 Breaking the Curse of Multiagency: Provably Efficient Decentralized Multi-Agent RL with Function Approximation.] \n
  Yuanhao Wang, Qinghua Liu, Yu Bai, Chi Jin. \n

- [http://arxiv.org/abs/2302.01333 Lower Bounds for Learning in Revealing POMDPs.] \n
  Fan Chen, Huan Wang, Caiming Xiong, Song Mei, Yu Bai. \n
  ICML 2023.
  
- [https://arxiv.org/abs/2302.07869 Improved Online Conformal Prediction via Strongly Adaptive Online Learning.] \n
  Aadyot Bhatnagar, Huan Wang, Caiming Xiong, Yu Bai. \n
  ICML 2023.
  
== Research Focus and Selected Publications

~~~
{Multi-Agent Reinforcement Learning Theory}

We developed the first line of provably efficient algorithms for multi-agent reinforcement learning.

- [https://arxiv.org/abs/2206.02640 Policy Optimization for Markov Games: Unified Framework and Faster Convergence.] \n
  Runyu Zhang, Qinghua Liu, Huan Wang, Caiming Xiong, Na Li, Yu Bai. \n
  NeurIPS 2022.

- [https://arxiv.org/abs/2110.04184 When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently?] \n
  Ziang Song, Song Mei, Yu Bai. \n
  ICLR 2022.

- [https://arxiv.org/abs/2006.12007 Near-Optimal Reinforcement Learning with Self-Play.] \n
  Yu Bai, Chi Jin, Tiancheng Yu. \n
  NeurIPS 2020. \n
  # Preliminary version appeared as /oral presentation/ at ICML 2020 Workshop on the Theoretical Foundations of Reinforcemnet Learning.

- [https://arxiv.org/abs/2002.04017 Provable Self-Play Algorithms for Competitive Reinforcement Learning.] \n
  Yu Bai, Chi Jin. \n
  ICML 2020.
~~~


~~~
{Deep Learning Theory}

We developed optimization and generalization results for overparametrized neural networks beyond the Neural Tangent Kenrels (NTK) regime, and identified provable advantages over the NTK regime.

- [https://arxiv.org/abs/2006.13436 Towards Understanding Hierarchical
  Learning: Benefits of Neural Representations.] \n
  Minshuo Chen, Yu Bai, Jason D. Lee, Tuo Zhao, Huan Wang, Caiming
  Xiong, Richard Socher. \n
  NeurIPS 2020. \n

- [https://arxiv.org/abs/1910.01619 Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks.] \n
  Yu Bai, Jason D. Lee. \n
  ICLR 2020.
~~~

~~~
{Partially Observable Reinforcement Learning}

We designed sharp sample-efficient algorithms and studied the fundamental limits for partially observable reinforcement learning.

- [http://arxiv.org/abs/2302.01333 Lower Bounds for Learning in Revealing POMDPs.] \n
  Fan Chen, Huan Wang, Caiming Xiong, Song Mei, Yu Bai. \n
  ICML 2023. \n

- [https://arxiv.org/abs/2209.14990 Partially Observable RL with B-Stability: Unified Structural Condition and Sharp Sample-Efficient Algorithms.] \n
  Fan Chen, Yu Bai, Song Mei. \n
  ICLR 2023 (*Notable-top-25% / "Spotlight"*).
~~~

~~~
{Learning in Games}

We designed near-optimal algorithms for learning equilibria in various multi-player games under bandit feedback.

- [https://arxiv.org/abs/2210.11402 Learning Rationalizable Equilibria in Multiplayer Games.] \n
  Yuanhao Wang, Dingwen Kong, Yu Bai, Chi Jin. \n
  ICLR 2023.

- [http://arxiv.org/abs/2205.15294 Efficient Phi-Regret Minimization in Extensive-Form Games via Online Mirror Descent.] \n
  Yu Bai, Chi Jin, Song Mei, Ziang Song, Tiancheng Yu. \n
  NeurIPS 2022 (*Oral*).

- [https://arxiv.org/abs/2205.07223 Sample-Efficient Learning of Correlated Equilibria in Extensive-Form Games.] \n
  Ziang Song, Song Mei, Yu Bai. \n
  NeurIPS 2022.

- [http://arxiv.org/abs/2202.01752 Near-Optimal Learning of Extensive-Form Games with Imperfect Information.] \n
  Yu Bai, Chi Jin, Song Mei, Tiancheng Yu. \n
  ICML 2022.
  # \n Preliminary version selected as /contributed talk/ at ICLR 2022 Workshop on Gamification and Multiagent Solutions.
~~~

~~~
{Uncertainty Quantification in Machine Learning}

We gave precise theoretical characterizations of the calibration and coverage of vanilla machine learning algorithms, and developed new uncertainty quantificaiton algorithms with valid guarantees and improved efficiency.

- [https://arxiv.org/abs/2202.11091 Efficient and Differentiable Conformal Prediction with General Function Classes.] \n
  Yu Bai, Song Mei, Huan Wang, Yingbo Zhou, Caiming Xiong. \n
  ICLR 2022. [https://github.com/allenbai01/cp-gen \[Code\]]


- [https://arxiv.org/abs/2106.05515 Understanding the Under-Coverage Bias in Uncertainty Estimation.] \n
  Yu Bai, Song Mei, Huan Wang, Caiming Xiong. \n
  NeurIPS 2021 (*Spotlight*). \n

- [https://arxiv.org/abs/2102.07856 Don't Just Blame Over-parametrization for Over-confidence: Theoretical Analysis of Calibration in Binary Classification.] \n
  Yu Bai, Song Mei, Huan Wang, Caiming Xiong. \n
  ICML 2021.
~~~
