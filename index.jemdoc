# jemdoc: menu{MENU}{index.html}
= Yu Bai

~~~
{}{img_left}{yub.png}{Yu Bai}{240}{320}{}

*About me*: I am a Senior Research Scientist at [https://www.salesforceairesearch.com/ Salesforce AI Research] in Palo Alto, CA. Before joining Salesforce, I completed my PhD in [https://statistics.stanford.edu/ Statistics] at [http://www.stanford.edu/ Stanford University] (specializing in machine learning) in September 2019, where I was fortunate to be advised by Prof. [https://stanford.edu/~jduchi/ John Duchi] and was a member of the [http://ml.stanford.edu/ Machine Learning Group]. During my PhD I also spent times at the research labs of Google and Amazon. Prior to Stanford, I was an undergrad in mathematics at [http://www.pku.edu.cn/ Peking University].

# During my PhD, I also spent two summers in research labs in the industry: at [https://research.google.com Google Research] in 2016, and at Amazon AI Palo Alto in 2018.

My research interest lies broadly in machine learning, with recent focus on
- Theoretical foundations of deep learning ([https://blog.salesforceairesearch.com/beyond-ntk/ blog post]);
- Reinforcement learning theory ([https://yubai.org/Slides/pomdp.pdf slides] on partially observable RL);
- Multi-agent reinforcement learning and games  ([https://yubai.org/blog/marl_theory.html blog post], [https://yubai.org/Slides/marl_lecture.pdf slides] on MARL, [https://yubai.org/Slides/efg.pdf slides] on Extensive-Form Games);
- Uncertainty quantification ([https://yubai.org/Slides/uncertainty.pdf slides]).

# My recent focus is on the theoretical foundations of deep learning, reinforcement learning, representation learning, and uncertainty quantification.

*News*:

# - *{{<font color="DarkBlue">Looking for self-motivated interns for summer 2021!</font>}}*

- \[Mar 2023\] I will serve as an Area Chair for NeurIPS 2023.

- \[Jan 2023\] Three papers accepted at ICLR 2023.

- \[Nov 2022\] Excited to be giving an invited talk "Recent Progresses on the Theory of Multi-Agent Reinforcement Learning and Games" at [https://cs332.stanford.edu Stanford CS332].

- \[Sep 2022\] Four papers accepted at NeurIPS 2022.

- \[May 2022\] Excited to be speaking at the [https://sites.google.com/view/rltheoryseminars/home?authuser=0 RL theory seminar] about our [https://arxiv.org/abs/2110.04184 work] on sample-efficient learning of general-sum Markov Games with a large number of players!

- \[May 2022\] Our [http://arxiv.org/abs/2202.01752 paper] on near-optimal learning in extensive-form games is accepted at ICML 2022. We achieve this by two new algorithms (Balanced OMD, Balanced CFR).

- \[Jan 2022\] Two papers accepted at ICLR 2022, on [https://arxiv.org/abs/2110.04184 sample-efficient RL in multi-agent general-sum Markov games], and [https://arxiv.org/abs/2202.11091 improved conformal prediction with general families of prediction sets].

# - \[Nov 2021\] New [https://yubai.org/blog/marl_theory.html blog post] (with Chi Jin) on recent progresses in multi-agent RL theory released!

# - \[Oct 2021\] Invited talk at Rutgers University ([https://statistics.rutgers.edu/news-events/seminars statistics department seminar]) on understanding the under-coverage bias in [https://arxiv.org/abs/2106.05515 uncertainty estimation] and [https://arxiv.org/abs/2102.07856 calibration].

# - \[Sep 2021\] Four papers accepted at NeurIPS 2021.

# - \[May 2021\] Four papers accepted at ICML 2021.

# - \[Mar 2021\] New blog post (cross-posted at [https://blog.einstein.ai/beyond-ntk/ Salesforce Research blog] and [http://www.offconvex.org/2021/03/25/beyondNTK/ off the convex path]) on our "Beyond NTK" line of work. We explore how to escape the "NTK ball" around the initialization, and why that can bring provable learning benefits to neural networks for learning certain functions.

# - \[Sep 2020\] Two papers accepted by NeurIPS 2020. Topics include  [https://arxiv.org/abs/2006.13436 new understandings of hierarchical learning in neural networks], and [https://arxiv.org/abs/2006.12007 near-optimal self-play algorithms for learning zero-sum Markov games].

# - \[May 2020\] Our [https://arxiv.org/abs/2002.04017 paper] on self-play is accepted by ICML 2020. We present the first line of provable self-play algorithms for two-player Markov games.

# - In October 2019, I will be joining [https://einstein.ai/ Salesforce Research] in Palo Alto as a research scientist. 

# - I am attending the [https://simons.berkeley.edu/programs/dl2019 Foundations of Deep Learning] program at the Simons Institute (Berkeley) as a research fellow in May - August 2019. 

*Contact*:

yu.bai (at) salesforce.com

[Yu_Bai_CV.pdf Curriculum Vitae] |
[https://scholar.google.com/citations?user=owqhKD8AAAAJ&hl=en&authuser=1
Google Scholar Profile] | [https://github.com/allenbai01 Github]

{{<a href="https://twitter.com/yubai01?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @yubai01</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>}}
~~~

== Research

* Preprints *

- [https://arxiv.org/abs/2302.06606 Breaking the Curse of Multiagency: Provably Efficient Decentralized Multi-Agent RL with Function Approximation.] \n
  Yuanhao Wang, Qinghua Liu, Yu Bai, Chi Jin. \n
 
- [http://arxiv.org/abs/2302.01333 Lower Bounds for Learning in Revealing POMDPs.] \n
  Fan Chen, Huan Wang, Caiming Xiong, Song Mei, Yu Bai. \n

- [https://arxiv.org/abs/2302.07869 Improved Online Conformal Prediction via Strongly Adaptive Online Learning.] \n
  Aadyot Bhatnagar, Huan Wang, Caiming Xiong, Yu Bai. \n
  
- [https://arxiv.org/abs/2302.02571 Offline Learning in Markov Games with General Function Approximation.] \n
  Yuheng Zhang, Yu Bai, Nan Jiang. \n

- [https://arxiv.org/abs/2209.11745 Unified Algorithms for RL with Decision-Estimation Coefficients: No-Regret, PAC, and Reward-Free Learning. ] \n
  Fan Chen, Song Mei, Yu Bai. \n

* Publications *

- [https://arxiv.org/abs/2209.14990 Partially Observable RL with B-Stability: Unified Structural Condition and Sharp Sample-Efficient Algorithms.] \n
  Fan Chen, Yu Bai, Song Mei. \n
  ICLR 2023 (*Notable-top-25% / "Spotlight"*).

- [https://arxiv.org/abs/2210.04157 The Role of Coverage in Online Reinforcement Learning.] \n
  Tengyang Xie, Dylan J. Foster, Yu Bai, Nan Jiang, Sham M. Kakade. \n
  ICLR 2023 (*Notable-top-5% / "Oral"*).

- [https://arxiv.org/abs/2210.11402 Learning Rationalizable Equilibria in Multiplayer Games.] \n
  Yuanhao Wang, Dingwen Kong, Yu Bai, Chi Jin. \n
  ICLR 2023.

- [http://arxiv.org/abs/2205.15294 Efficient Phi-Regret Minimization in Extensive-Form Games via Online Mirror Descent.] \n
  Yu Bai, Chi Jin, Song Mei, Ziang Song, Tiancheng Yu. \n
  NeurIPS 2022 (*Oral*).

- [https://arxiv.org/abs/2206.02640 Policy Optimization for Markov Games: Unified Framework and Faster Convergence.] \n
  Runyu Zhang, Qinghua Liu, Huan Wang, Caiming Xiong, Na Li, Yu Bai. \n
  NeurIPS 2022.

- [https://arxiv.org/abs/2206.03688 Identifying Good Directions to Escape the NTK Regime and Efficiently Learn Low-Degree Plus Sparse Polynomials.] \n
  Eshaan Nichani, Yu Bai, Jason D. Lee. \n
  NeurIPS 2022.

- [https://arxiv.org/abs/2205.07223 Sample-Efficient Learning of Correlated Equilibria in Extensive-Form Games.] \n
  Ziang Song, Song Mei, Yu Bai. \n
  NeurIPS 2022.

- [https://arxiv.org/abs/2210.12619 Conformal Predictor for Improving Zero-Shot Text Classification Efficiency.] \n
  Prafulla Kumar Choubey, Yu Bai, Chien-Sheng Wu, Wenhao Liu, Nazneen Rajani. \n
  EMNLP 2022.
  
- [https://arxiv.org/abs/2102.10809 Local Calibration: Metrics and Recalibration.] \n
  Rachel Luo, Aadyot Bhatnagar, Yu Bai, Shengjia Zhao, Huan Wang, Caiming Xiong, Silvio Savarese, Edward Schmerling, Marco Pavone. \n
  UAI 2022.
  
- [http://arxiv.org/abs/2202.01752 Near-Optimal Learning of Extensive-Form Games with Imperfect Information.] \n
  Yu Bai, Chi Jin, Song Mei, Tiancheng Yu. \n
  ICML 2022.
  # \n Preliminary version selected as /contributed talk/ at ICLR 2022 Workshop on Gamification and Multiagent Solutions.

- [https://arxiv.org/abs/2110.04184 When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently?] \n
  Ziang Song, Song Mei, Yu Bai. \n
  ICLR 2022.

- [https://arxiv.org/abs/2202.11091 Efficient and Differentiable Conformal Prediction with General Function Classes.] \n
  Yu Bai, Song Mei, Huan Wang, Yingbo Zhou, Caiming Xiong. \n
  ICLR 2022. [https://github.com/allenbai01/cp-gen \[Code\]]
  
- [https://arxiv.org/abs/2106.05515 Understanding the Under-Coverage Bias in Uncertainty Estimation.] \n
  Yu Bai, Song Mei, Huan Wang, Caiming Xiong. \n
  NeurIPS 2021 (*Spotlight*). \n
  # Appearing as /spotlight presentation/ at ICML 2021 Workshop on Distribution-Free Uncertainty Quantification. \n
  # Also appearing at ICML 2021 Workshop on Uncertainty \& Robustness in Deep Learning.
  
- [https://arxiv.org/abs/2106.04895 Policy Finetuning: Bridging Sample-Efficient Offline and Online Reinforcement Learning.] \n
  Tengyang Xie, Nan Jiang, Huan Wang, Caiming Xiong, Yu Bai. \n
  NeurIPS 2021. \n
  # Appearing at ICML 2021 Workshop on Reinforcement Learning Theory.
  
- [https://arxiv.org/abs/2102.11494 Sample-Efficient Learning of Stackelberg Equilibria in General-Sum Games.] \n
  Yu Bai, Chi Jin, Huan Wang, Caiming Xiong. \n
  NeurIPS 2021. \n
  # Appearing as /spotlight presentation/ at ICML 2021 Workshop on Reinforcement Learning Theory.
  
- [https://arxiv.org/abs/2102.01748 Near-Optimal Offline Reinforcement Learning via Double Variance Reduction.] \n
  Ming Yin, Yu Bai, Yu-Xiang Wang. \n
  NeurIPS 2021. \n
  # Appearing at ICML 2021 Workshop on Reinforcement Learning Theory.
  
- [https://arxiv.org/abs/2102.07856 Don't Just Blame Over-parametrization for Over-confidence: Theoretical Analysis of Calibration in Binary Classification.] \n
  Yu Bai, Song Mei, Huan Wang, Caiming Xiong. \n
  ICML 2021.

- [https://arxiv.org/abs/2103.04554 Exact Gap between Generalization Error and Uniform Convergence in Random Feature Models.] \n
  Zitong Yang, Yu Bai, Song Mei. \n
  ICML 2021.

- [http://arxiv.org/abs/2010.05843 How Important is the Train-Validation Split in Meta-Learning?] \n
  Yu Bai, Minshuo Chen, Pan Zhou, Tuo Zhao, Jason D. Lee, Sham Kakade, Huan Wang, Caiming Xiong. \n
  ICML 2021.
  # Preliminary version appearing at NeurIPS 2020 workshop on Meta-Learning.

- [http://arxiv.org/abs/2010.01604 A Sharp Analysis of Model-based Reinforcement Learning with Self-Play.] \n
  Qinghua Liu, Tiancheng Yu, Yu Bai, Chi Jin. \n
  ICML 2021.


- [https://arxiv.org/abs/2007.03760 Near Optimal Provable Uniform
  Convergence in Off-Policy Evaluation for Reinforcement Learning.] \n
  Ming Yin, Yu Bai, Yu-Xiang Wang. \n
  AISTATS 2021 (*Oral*).  \n
  # Preliminary version appearing at NeurIPS 2020 workshop on Offline Reinforcement Learning.
  
- [https://arxiv.org/abs/2006.13436 Towards Understanding Hierarchical
  Learning: Benefits of Neural Representations.] \n
  Minshuo Chen, Yu Bai, Jason D. Lee, Tuo Zhao, Huan Wang, Caiming
  Xiong, Richard Socher. \n
  NeurIPS 2020. \n

- [https://arxiv.org/abs/2006.12007 Near-Optimal Reinforcement
  Learning with Self-Play.] \n
  Yu Bai, Chi Jin, Tiancheng Yu. \n
  NeurIPS 2020. \n
  # Preliminary version appeared as /oral presentation/ at ICML 2020 Workshop on the Theoretical Foundations of Reinforcemnet Learning.

- [https://arxiv.org/abs/2002.04017 Provable Self-Play Algorithms for Competitive Reinforcement Learning.] \n
  Yu Bai, Chi Jin. \n
  ICML 2020.
  
- [https://arxiv.org/abs/1910.01619 Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks.] \n
  Yu Bai, Jason D. Lee. \n
  ICLR 2020.
  
- [https://arxiv.org/abs/1905.12849 Provably Efficient Q-Learning with Low Switching Cost.] \n
  Yu Bai, Tengyang Xie, Nan Jiang, Yu-Xiang Wang. \n
  NeurIPS 2019.
  
- [https://arxiv.org/abs/1810.10702
  Subgradient Descent Learns Orthogonal Dictionaries.] \n
  Yu Bai, Qijia Jiang, Ju Sun. \n
  ICLR 2019.

- [https://arxiv.org/abs/1810.00861 
  ProxQuant: Quantized Neural Networks via Proximal Operators.] \n
  Yu Bai, Yu-Xiang Wang, Edo Liberty. \n
  ICLR 2019. [https://github.com/allenbai01/ProxQuant \[Code\]]

- [https://arxiv.org/abs/1806.10586 Approximability of Discriminators
  Implies Diversity in GANs.] \n
  Yu Bai, Tengyu Ma, Andrej Risteski. \n
  ICLR 2019.

- [https://arxiv.org/abs/1607.06534 The Landscape of Empirical Risk
  for Nonconvex Losses.] \n
  Song Mei, Yu Bai, Andrea Montanari, 2016.
  \n /The Annals of Statistics,/ Volume 46, Number 6A (2018), 2747-2774.

* Other technical reports *


- [https://arxiv.org/abs/2201.01163 Finding General Equilibria in Many-Agent Economic Simulations Using Deep Reinforcement Learning. ] \n
  Michael Curry, Alexander Trott, Soham Phade, Yu Bai, Stephan Zheng. \n

- [https://arxiv.org/abs/2002.04010 Taylorized Training: Towards Better Approximation of Neural Network Training at Finite Width.] \n
  Yu Bai, Ben Krause, Huan Wang, Caiming Xiong, Richard Socher. \n
  [https://github.com/allenbai01/taylorized-training \[Code\]]

- [https://arxiv.org/abs/1903.00184 Proximal algorithms for constrained composite optimization, with applications to solving low-rank SDPs.] \n
  Yu Bai, John C. Duchi, Song Mei. \n
  # Preprint, 2019.

- [https://arxiv.org/abs/1805.08756 Analysis of Sequantial Quadratic
  Programming through the Lens of Riemannian Optimization.] \n
  Yu Bai, Song Mei. \n
  # 2018.
  
- [https://arxiv.org/abs/1707.03073 TAPAS: Two-pass Approximate
  Adaptive Sampling for Softmax.] \n
  Yu Bai, Sally Goldman, Li Zhang. \n
  # 2017. 

== Talks

- When Can We Learn General-Sum Markov Games Sample-Efficiently with A Large Number of Players? \n
  RL Theory Virtual Seminars, May 2022.
  
- Near-Optimal Learning of Extensive-Form Games with Imperfect Information. \n
  Learning and Games Program, Simons Institute, April 2022. \n
  CISS Conference, Princeton University, March 2022.


- Understanding the Under-Coverage Bias in Uncertainty Estimation. \n
  Statistics Department Seminar, Rutgers University, October 2021. \n
  Spotlight presentation at ICML 2021 Workshop on Distribution-free Uncertainty Quantification, July 2021.

- Sample-Efficient Learning of Stackelberg Equilibria in General-Sum Games. \n
  Spotlight presentation at ICML 2021 Workshop on Reinforcement Learning Theory, July 2021.

- How Important is the Train-Validtaion Split in Meta-Learning? \n
  One World Seminar on the Mathematics of Machine Learning, October 2020.

- Provable Self-Play Algorithms for Competitive Reinforcement Learning. \n
  ICML, July 2020. \n
  Facebook AI Research, March 2020.
  
- Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks. \n
  Simons Institute, August 2020. \n
  ICLR, April 2020.
  
- Subgradient Descent Learns Orthogonal Dictionaries. \n
  ICLR, May 2019, New Orleans, LA. \n
  
- ProxQuant: Quantized Neural Networks via Proximal Operators \n
  ICLR, May 2019, New Orleans, LA. \n
  Bytedance AI Lab, Dec 2018, Menlo Park, CA. \n
  Amazon AI, Sep 2018, East Palo Alto, CA.

- On the Generalization and Approximation in Generative Adversarial Networks (GANs) \n
  ICLR, May 2019, New Orleans, LA. \n
  Google Brain, Nov 2018, Mountain View, CA. \n
  Salesforce Research, Nov 2018, Palo Alto, CA. \n
  Stanford ML Seminar, Oct 2018, Stanford, CA.

- Optimization Landscape of some Non-convex Learning Problems \n
  Stanford Theory Seminar, Apr 2018, Stanford, CA. \n
  Stanford ML Seminar, Apr 2017, Stanford, CA.

== Service

- Area chair / Senior program committee: NeurIPS (2023), AIStats (2023). \n

- Conference reviewing:  NeurIPS (2018-2022), ICLR (2019-2023), ICML (2019-2021, 2023), COLT (2019-2020, 2022-2023), FOCS (2022), AIStats (2020), IEEE-ISIT (2018). \n

- Journal reviewing: TMLR (Transactions of Machine Learning Research), The Annals of Statistics, JASA (Journal of the American Statistical Association), JRSS-B (Journal of the Royal Statistical Society: Series B), JMLR (Journal of Machine Learning Research), IEEE-TSP (Transactions on Signal Processing), SICON (SIAM Journal on
Control and Optimization).



