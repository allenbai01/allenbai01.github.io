<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-5H5S8N88V2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-5H5S8N88V2');
</script>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publications</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Yu Bai</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="publications.html" class="current">Publications</a></div>
<div class="menu-item"><a href="talks.html">Talks</a></div>
<div class="menu-item"><a href="service.html">Service</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="blog/marl_theory.html">MARL&nbsp;Blog</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications</h1>
</div>
<p><b> Preprints </b></p>
<ul>
<li><p><a href="https://arxiv.org/abs/2312.00054">Is Inverse Reinforcement Learning Harder than Standard Reinforcement Learning?</a> <br />
Lei Zhao, Mengdi Wang, Yu Bai.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2209.11745">Unified Algorithms for RL with Decision-Estimation Coefficients: No-Regret, PAC, and Reward-Free Learning.</a> <br />
Fan Chen, Song Mei, Yu Bai. <br /></p>
</li>
</ul>
<p><b> Publications </b></p>
<ul>
<li><p><a href="https://arxiv.org/abs/2310.10616">How Do Transformers Learn In-Context Beyond Simple Functions? A Case Study on Learning with Representations.</a> <br />
Tianyu Guo, Wei Hu, Song Mei, Huan Wang, Caiming Xiong, Silvio Savarese, Yu Bai. <br />
ICLR 2024.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2310.08566">Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining.</a> <br />
Licong Lin, Yu Bai, Song Mei. <br />
ICLR 2024.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2307.02884">Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight.</a> <br />
Jiacheng Guo, Minshuo Chen, Huan Wang, Caiming Xiong, Mengdi Wang, Yu Bai. <br />
ICLR 2024.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2306.04637">Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection.</a> <br />
Yu Bai, Fan Chen, Huan Wang, Caiming Xiong, Song Mei. <br />
NeurIPS 2023 (<b>Oral</b>).

<a href="https://github.com/allenbai01/transformers-as-statisticians">[Code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2307.11353">What can a Single Attention Layer Learn? A Study Through the Random Features Lens.</a> <br />
Hengyu Fu, Tianyu Guo, Yu Bai, Song Mei. <br />
NeurIPS 2023.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2306.01243">Efficient RL with Impaired Observability: Learning to Act with Delayed and Missing State Observations.</a> <br />
Minshuo Chen, Yu Bai, H. Vincent Poor, Mengdi Wang. <br />
NeurIPS 2023.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2302.06606">Breaking the Curse of Multiagency: Provably Efficient Decentralized Multi-Agent RL with Function Approximation.</a> <br />
Yuanhao Wang, Qinghua Liu, Yu Bai, Chi Jin. <br />
COLT 2023.</p>
</li>
</ul>
<ul>
<li><p><a href="http://arxiv.org/abs/2302.01333">Lower Bounds for Learning in Revealing POMDPs.</a> <br />
Fan Chen, Huan Wang, Caiming Xiong, Song Mei, Yu Bai. <br />
ICML 2023.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2302.07869">Improved Online Conformal Prediction via Strongly Adaptive Online Learning.</a> <br />
Aadyot Bhatnagar, Huan Wang, Caiming Xiong, Yu Bai. <br />
ICML 2023.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2302.02571">Offline Learning in Markov Games with General Function Approximation.</a> <br />
Yuheng Zhang, Yu Bai, Nan Jiang. <br />
ICML 2023.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2209.14990">Partially Observable RL with B-Stability: Unified Structural Condition and Sharp Sample-Efficient Algorithms.</a> <br />
Fan Chen, Yu Bai, Song Mei. <br />
ICLR 2023 (<b>Notable-top-25% / &ldquo;Spotlight&rdquo;</b>).</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2210.04157">The Role of Coverage in Online Reinforcement Learning.</a> <br />
Tengyang Xie, Dylan J. Foster, Yu Bai, Nan Jiang, Sham M. Kakade. <br />
ICLR 2023 (<b>Notable-top-5% / &ldquo;Oral&rdquo;</b>).</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2210.11402">Learning Rationalizable Equilibria in Multiplayer Games.</a> <br />
Yuanhao Wang, Dingwen Kong, Yu Bai, Chi Jin. <br />
ICLR 2023.</p>
</li>
</ul>
<ul>
<li><p><a href="http://arxiv.org/abs/2205.15294">Efficient Phi-Regret Minimization in Extensive-Form Games via Online Mirror Descent.</a> <br />
Yu Bai, Chi Jin, Song Mei, Ziang Song, Tiancheng Yu. <br />
NeurIPS 2022 (<b>Oral</b>).</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2206.02640">Policy Optimization for Markov Games: Unified Framework and Faster Convergence.</a> <br />
Runyu Zhang, Qinghua Liu, Huan Wang, Caiming Xiong, Na Li, Yu Bai. <br />
NeurIPS 2022.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2206.03688">Identifying Good Directions to Escape the NTK Regime and Efficiently Learn Low-Degree Plus Sparse Polynomials.</a> <br />
Eshaan Nichani, Yu Bai, Jason D. Lee. <br />
NeurIPS 2022.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2205.07223">Sample-Efficient Learning of Correlated Equilibria in Extensive-Form Games.</a> <br />
Ziang Song, Song Mei, Yu Bai. <br />
NeurIPS 2022.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2210.12619">Conformal Predictor for Improving Zero-Shot Text Classification Efficiency.</a> <br />
Prafulla Kumar Choubey, Yu Bai, Chien-Sheng Wu, Wenhao Liu, Nazneen Rajani. <br />
EMNLP 2022.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2102.10809">Local Calibration: Metrics and Recalibration.</a> <br />
Rachel Luo, Aadyot Bhatnagar, Yu Bai, Shengjia Zhao, Huan Wang, Caiming Xiong, Silvio Savarese, Edward Schmerling, Marco Pavone. <br />
UAI 2022.</p>
</li>
</ul>
<ul>
<li><p><a href="http://arxiv.org/abs/2202.01752">Near-Optimal Learning of Extensive-Form Games with Imperfect Information.</a> <br />
Yu Bai, Chi Jin, Song Mei, Tiancheng Yu. <br />
ICML 2022.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2110.04184">When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently?</a> <br />
Ziang Song, Song Mei, Yu Bai. <br />
ICLR 2022.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2202.11091">Efficient and Differentiable Conformal Prediction with General Function Classes.</a> <br />
Yu Bai, Song Mei, Huan Wang, Yingbo Zhou, Caiming Xiong. <br />
ICLR 2022. <a href="https://github.com/allenbai01/cp-gen">[Code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2106.05515">Understanding the Under-Coverage Bias in Uncertainty Estimation.</a> <br />
Yu Bai, Song Mei, Huan Wang, Caiming Xiong. <br />
NeurIPS 2021 (<b>Spotlight</b>). <br />

</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2106.04895">Policy Finetuning: Bridging Sample-Efficient Offline and Online Reinforcement Learning.</a> <br />
Tengyang Xie, Nan Jiang, Huan Wang, Caiming Xiong, Yu Bai. <br />
NeurIPS 2021. <br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2102.11494">Sample-Efficient Learning of Stackelberg Equilibria in General-Sum Games.</a> <br />
Yu Bai, Chi Jin, Huan Wang, Caiming Xiong. <br />
NeurIPS 2021. <br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2102.01748">Near-Optimal Offline Reinforcement Learning via Double Variance Reduction.</a> <br />
Ming Yin, Yu Bai, Yu-Xiang Wang. <br />
NeurIPS 2021. <br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2102.07856">Don't Just Blame Over-parametrization for Over-confidence: Theoretical Analysis of Calibration in Binary Classification.</a> <br />
Yu Bai, Song Mei, Huan Wang, Caiming Xiong. <br />
ICML 2021.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2103.04554">Exact Gap between Generalization Error and Uniform Convergence in Random Feature Models.</a> <br />
Zitong Yang, Yu Bai, Song Mei. <br />
ICML 2021.</p>
</li>
</ul>
<ul>
<li><p><a href="http://arxiv.org/abs/2010.05843">How Important is the Train-Validation Split in Meta-Learning?</a> <br />
Yu Bai, Minshuo Chen, Pan Zhou, Tuo Zhao, Jason D. Lee, Sham Kakade, Huan Wang, Caiming Xiong. <br />
ICML 2021.
</p>
</li>
</ul>
<ul>
<li><p><a href="http://arxiv.org/abs/2010.01604">A Sharp Analysis of Model-based Reinforcement Learning with Self-Play.</a> <br />
Qinghua Liu, Tiancheng Yu, Yu Bai, Chi Jin. <br />
ICML 2021.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2007.03760">Near Optimal Provable Uniform
Convergence in Off-Policy Evaluation for Reinforcement Learning.</a> <br />
Ming Yin, Yu Bai, Yu-Xiang Wang. <br />
AISTATS 2021 (<b>Oral</b>).  <br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2006.13436">Towards Understanding Hierarchical
Learning: Benefits of Neural Representations.</a> <br />
Minshuo Chen, Yu Bai, Jason D. Lee, Tuo Zhao, Huan Wang, Caiming
Xiong, Richard Socher. <br />
NeurIPS 2020. <br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2006.12007">Near-Optimal Reinforcement
Learning with Self-Play.</a> <br />
Yu Bai, Chi Jin, Tiancheng Yu. <br />
NeurIPS 2020. <br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2002.04017">Provable Self-Play Algorithms for Competitive Reinforcement Learning.</a> <br />
Yu Bai, Chi Jin. <br />
ICML 2020.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1910.01619">Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks.</a> <br />
Yu Bai, Jason D. Lee. <br />
ICLR 2020.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1905.12849">Provably Efficient Q-Learning with Low Switching Cost.</a> <br />
Yu Bai, Tengyang Xie, Nan Jiang, Yu-Xiang Wang. <br />
NeurIPS 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1810.10702">Subgradient Descent Learns Orthogonal Dictionaries.</a> <br />
Yu Bai, Qijia Jiang, Ju Sun. <br />
ICLR 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1810.00861">ProxQuant: Quantized Neural Networks via Proximal Operators.</a> <br />
Yu Bai, Yu-Xiang Wang, Edo Liberty. <br />
ICLR 2019. <a href="https://github.com/allenbai01/ProxQuant">[Code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1806.10586">Approximability of Discriminators
Implies Diversity in GANs.</a> <br />
Yu Bai, Tengyu Ma, Andrej Risteski. <br />
ICLR 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1607.06534">The Landscape of Empirical Risk
for Nonconvex Losses.</a> <br />
Song Mei, Yu Bai, Andrea Montanari, 2016.
<br /> <i>The Annals of Statistics,</i> Volume 46, Number 6A (2018), 2747-2774.</p>
</li>
</ul>
<p><b> Other technical reports </b></p>
<ul>
<li><p><a href="https://arxiv.org/abs/2201.01163">Finding General Equilibria in Many-Agent Economic Simulations Using Deep Reinforcement Learning.</a> <br />
Michael Curry, Alexander Trott, Soham Phade, Yu Bai, Stephan Zheng. <br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2002.04010">Taylorized Training: Towards Better Approximation of Neural Network Training at Finite Width.</a> <br />
Yu Bai, Ben Krause, Huan Wang, Caiming Xiong, Richard Socher. <br />
<a href="https://github.com/allenbai01/taylorized-training">[Code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1903.00184">Proximal algorithms for constrained composite optimization, with applications to solving low-rank SDPs.</a> <br />
Yu Bai, John C. Duchi, Song Mei. <br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1805.08756">Analysis of Sequantial Quadratic
Programming through the Lens of Riemannian Optimization.</a> <br />
Yu Bai, Song Mei. <br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1707.03073">TAPAS: Two-pass Approximate
Adaptive Sampling for Softmax.</a> <br />
Yu Bai, Sally Goldman, Li Zhang. <br />
</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2024-01-16 10:07:57 PST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
