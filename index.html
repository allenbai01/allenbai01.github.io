<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Yu Bai</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Yu Bai</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="blog/marl_theory.html">MARL&nbsp;Blog</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Yu Bai</h1>
</div>
<table class="imgtable"><tr><td>
<img src="yub.png" alt="Yu Bai" width="240px" height="320px" />&nbsp;</td>
<td align="left"><p><b>About me</b>: I am a Senior Research Scientist at <a href="https://www.salesforceairesearch.com/">Salesforce AI Research</a> in Palo Alto, CA. Before joining Salesforce, I completed my PhD in <a href="https://statistics.stanford.edu/">Statistics</a> at <a href="http://www.stanford.edu/">Stanford University</a> (specializing in machine learning) in September 2019, where I was fortunate to be advised by Prof. <a href="https://stanford.edu/~jduchi/">John Duchi</a> and was a member of the <a href="http://ml.stanford.edu/">Machine Learning Group</a>. During my PhD I also spent times at the research labs of Google and Amazon. Prior to Stanford, I was an undergrad in mathematics at <a href="http://www.pku.edu.cn/">Peking University</a>.</p>
<p>My research interest lies broadly in machine learning, with recent focus on</p>
<ul>
<li><p>Multi-agent reinforcement learning and games;</p>
</li>
<li><p>Uncertainty quantification;</p>
</li>
<li><p>Theoretical foundations of deep learning.</p>
</li>
</ul>
<p><b>News</b>:</p>
<ul>
<li><p>[Jan 2022] Two papers accepted at ICLR 2022, on <a href="https://arxiv.org/abs/2110.04184">sample-efficient RL in multi-agent general-sum Markov games</a>, and <a href="https://arxiv.org/abs/2202.11091">improved conformal prediction with general families of prediction sets</a>.</p>
</li>
</ul>
<ul>
<li><p>[Nov 2021] New <a href="https://yubai.org/blog/marl_theory.html">blog post</a> (with Chi Jin) on recent progresses in multi-agent RL theory released!</p>
</li>
</ul>
<ul>
<li><p>[Oct 2021] Invited talk at Rutgers University (<a href="https://statistics.rutgers.edu/news-events/seminars">statistics department seminar</a>) on understanding the under-coverage bias in <a href="https://arxiv.org/abs/2106.05515">uncertainty estimation</a> and <a href="https://arxiv.org/abs/2102.07856">calibration</a>.</p>
</li>
</ul>
<ul>
<li><p>[Sep 2021] Four papers accepted at NeurIPS 2021.</p>
</li>
</ul>
<ul>
<li><p>[May 2021] Four papers accepted at ICML 2021.</p>
</li>
</ul>
<ul>
<li><p>[Mar 2021] New blog post (cross-posted at <a href="https://blog.einstein.ai/beyond-ntk/">Salesforce Research blog</a> and <a href="http://www.offconvex.org/2021/03/25/beyondNTK/">off the convex path</a>) on our &ldquo;Beyond NTK&rdquo; line of work. We explore how to escape the &ldquo;NTK ball&rdquo; around the initialization, and why that can bring provable learning benefits to neural networks for learning certain functions.</p>
</li>
</ul>
<p><b>Contact</b>:</p>
<p>yu.bai (at) salesforce.com</p>
<p><a href="Yu_Bai_CV.pdf">Curriculum Vitae</a> |
<a href="https://scholar.google.com/citations?user=owqhKD8AAAAJ&amp;hl=en&amp;authuser=1">Google Scholar Profile</a> | <a href="https://github.com/allenbai01">Github</a></p>
<p><a href="https://twitter.com/yubai01?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @yubai01</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p>
</td></tr></table>
<h2>Research</h2>
<p><b> Preprints </b></p>
<ul>
<li><p><a href="http://arxiv.org/abs/2202.01752">Near-Optimal Learning of Extensive-Form Games with Imperfect Information.</a> <br />
Yu Bai, Chi Jin, Song Mei, Tiancheng Yu. <br />
Preprint, 2022. <br />
Preliminary version selected as <i>contributed talk</i> at ICLR 2022 Workshop on Gamification and Multiagent Solutions.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2201.01163">Finding General Equilibria in Many-Agent Economic Simulations Using Deep Reinforcement Learning.</a> <br />
Michael Curry, Alexander Trott, Soham Phade, Yu Bai, Stephan Zheng. <br />
Preprint, 2022. <br /></p>
</li>
</ul>
<p><b> Publications </b></p>
<ul>
<li><p><a href="https://arxiv.org/abs/2110.04184">When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently?</a> <br />
Ziang Song, Song Mei, Yu Bai. <br />
ICLR 2022.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2202.11091">Efficient and Differentiable Conformal Prediction with General Function Classes.</a> <br />
Yu Bai, Song Mei, Huan Wang, Yingbo Zhou, Caiming Xiong. <br />
ICLR 2022. <a href="https://github.com/allenbai01/cp-gen">[Code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2106.05515">Understanding the Under-Coverage Bias in Uncertainty Estimation.</a> <br />
Yu Bai, Song Mei, Huan Wang, Caiming Xiong. <br />
NeurIPS 2021 (spotlight presentation). <br />

</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2106.04895">Policy Finetuning: Bridging Sample-Efficient Offline and Online Reinforcement Learning.</a> <br />
Tengyang Xie, Nan Jiang, Huan Wang, Caiming Xiong, Yu Bai. <br />
NeurIPS 2021. <br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2102.11494">Sample-Efficient Learning of Stackelberg Equilibria in General-Sum Games.</a> <br />
Yu Bai, Chi Jin, Huan Wang, Caiming Xiong. <br />
NeurIPS 2021. <br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2102.01748">Near-Optimal Offline Reinforcement Learning via Double Variance Reduction.</a> <br />
Ming Yin, Yu Bai, Yu-Xiang Wang. <br />
NeurIPS 2021. <br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2102.07856">Don't Just Blame Over-parametrization for Over-confidence: Theoretical Analysis of Calibration in Binary Classification.</a> <br />
Yu Bai, Song Mei, Huan Wang, Caiming Xiong. <br />
ICML 2021.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2103.04554">Exact Gap between Generalization Error and Uniform Convergence in Random Feature Models.</a> <br />
Zitong Yang, Yu Bai, Song Mei. <br />
ICML 2021.</p>
</li>
</ul>
<ul>
<li><p><a href="http://arxiv.org/abs/2010.05843">How Important is the Train-Validation Split in Meta-Learning?</a> <br />
Yu Bai, Minshuo Chen, Pan Zhou, Tuo Zhao, Jason D. Lee, Sham Kakade, Huan Wang, Caiming Xiong. <br />
ICML 2021.
</p>
</li>
</ul>
<ul>
<li><p><a href="http://arxiv.org/abs/2010.01604">A Sharp Analysis of Model-based Reinforcement Learning with Self-Play.</a> <br />
Qinghua Liu, Tiancheng Yu, Yu Bai, Chi Jin. <br />
ICML 2021.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2007.03760">Near Optimal Provable Uniform
Convergence in Off-Policy Evaluation for Reinforcement Learning.</a> <br />
Ming Yin, Yu Bai, Yu-Xiang Wang. <br />
AISTATS 2021 (oral presentation).  <br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2006.13436">Towards Understanding Hierarchical
Learning: Benefits of Neural Representations.</a> <br />
Minshuo Chen, Yu Bai, Jason D. Lee, Tuo Zhao, Huan Wang, Caiming
Xiong, Richard Socher. <br />
NeurIPS 2020. <br /></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2006.12007">Near-Optimal Reinforcement
Learning with Self-Play.</a> <br />
Yu Bai, Chi Jin, Tiancheng Yu. <br />
NeurIPS 2020. <br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2002.04017">Provable Self-Play Algorithms for Competitive Reinforcement Learning.</a> <br />
Yu Bai, Chi Jin. <br />
ICML 2020.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1910.01619">Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks.</a> <br />
Yu Bai, Jason D. Lee. <br />
ICLR 2020.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1905.12849">Provably Efficient Q-Learning with Low Switching Cost.</a> <br />
Yu Bai, Tengyang Xie, Nan Jiang, Yu-Xiang Wang. <br />
NeurIPS 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1810.10702">Subgradient Descent Learns Orthogonal Dictionaries.</a> <br />
Yu Bai, Qijia Jiang, Ju Sun. <br />
ICLR 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1810.00861">ProxQuant: Quantized Neural Networks via Proximal Operators.</a> <br />
Yu Bai, Yu-Xiang Wang, Edo Liberty. <br />
ICLR 2019. <a href="https://github.com/allenbai01/ProxQuant">[Code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1806.10586">Approximability of Discriminators
Implies Diversity in GANs.</a> <br />
Yu Bai, Tengyu Ma, Andrej Risteski. <br />
ICLR 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1607.06534">The Landscape of Empirical Risk
for Nonconvex Losses.</a> <br />
Song Mei, Yu Bai, Andrea Montanari, 2016.
<br /> <i>The Annals of Statistics,</i> Volume 46, Number 6A (2018), 2747-2774.</p>
</li>
</ul>
<p><b> Other technical reports </b></p>
<ul>
<li><p><a href="https://arxiv.org/abs/2002.04010">Taylorized Training: Towards Better Approximation of Neural Network Training at Finite Width.</a> <br />
Yu Bai, Ben Krause, Huan Wang, Caiming Xiong, Richard Socher. <br />
Preprint, 2020. <a href="https://github.com/allenbai01/taylorized-training">[Code]</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1903.00184">Proximal algorithms for constrained composite optimization, with applications to solving low-rank SDPs.</a> <br />
Yu Bai, John C. Duchi, Song Mei. <br />
Preprint, 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1805.08756">Analysis of Sequantial Quadratic
Programming through the Lens of Riemannian Optimization.</a> <br />
Yu Bai, Song Mei, 2018.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1707.03073">TAPAS: Two-pass Approximate
Adaptive Sampling for Softmax.</a> <br />
Yu Bai, Sally Goldman, Li Zhang, 2017. </p>
</li>
</ul>
<h2>Talks</h2>
<ul>
<li><p>Near-Optimal Learning of Extensive-Form Games with Imperfect Information. <br />
Learning and Games Program, Simons Institute, April 2022. <br />
CISS Conference, Princeton University, March 2022.</p>
</li>
</ul>
<ul>
<li><p>Understanding the Under-Coverage Bias in Uncertainty Estimation. <br />
Statistics Department Seminar, Rutgers University, October 2021. <br />
Spotlight presentation at ICML 2021 Workshop on Distribution-free Uncertainty Quantification, July 2021.</p>
</li>
</ul>
<ul>
<li><p>Sample-Efficient Learning of Stackelberg Equilibria in General-Sum Games. <br />
Spotlight presentation at ICML 2021 Workshop on Reinforcement Learning Theory, July 2021.</p>
</li>
</ul>
<ul>
<li><p>How Important is the Train-Validtaion Split in Meta-Learning? <br />
One World Seminar on the Mathematics of Machine Learning, October 2020.</p>
</li>
</ul>
<ul>
<li><p>Provable Self-Play Algorithms for Competitive Reinforcement Learning. <br />
ICML, July 2020. <br />
Facebook AI Research, March 2020.</p>
</li>
</ul>
<ul>
<li><p>Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks. <br />
Simons Institute, August 2020. <br />
ICLR, April 2020.</p>
</li>
</ul>
<ul>
<li><p>Subgradient Descent Learns Orthogonal Dictionaries. <br />
ICLR, May 2019, New Orleans, LA. <br /></p>
</li>
</ul>
<ul>
<li><p>ProxQuant: Quantized Neural Networks via Proximal Operators <br />
ICLR, May 2019, New Orleans, LA. <br />
Bytedance AI Lab, Dec 2018, Menlo Park, CA. <br />
Amazon AI, Sep 2018, East Palo Alto, CA.</p>
</li>
</ul>
<ul>
<li><p>On the Generalization and Approximation in Generative Adversarial Networks (GANs) <br />
ICLR, May 2019, New Orleans, LA. <br />
Google Brain, Nov 2018, Mountain View, CA. <br />
Salesforce Research, Nov 2018, Palo Alto, CA. <br />
Stanford ML Seminar, Oct 2018, Stanford, CA.</p>
</li>
</ul>
<ul>
<li><p>Optimization Landscape of some Non-convex Learning Problems <br />
Stanford Theory Seminar, Apr 2018, Stanford, CA. <br />
Stanford ML Seminar, Apr 2017, Stanford, CA.</p>
</li>
</ul>
<h2>Service</h2>
<ul>
<li><p>Conference reviewing:  NeurIPS (2018-2021, top 30% reviewer in 2018), ICLR (2019-2022), ICML (2019-2021), COLT (2019-2020, 2022), AIStats (2020), IEEE-ISIT (2018). <br /></p>
</li>
</ul>
<ul>
<li><p>Journal reviewing: TMLR (Transactions of Machine Learning Research), The Annals of Statistics, JASA (Journal of the American Statistical Association), JRSS-B (Journal of the Royal Statistical Society: Series B), JMLR (Journal of Machine Learning Research), IEEE-TSP (Transactions on Signal Processing), SICON (SIAM Journal on
Control and Optimization).</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2022-04-30 18:38:08 PDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-101507093-1', 'auto');
  ga('send', 'pageview');
</script>
</body>
</html>
